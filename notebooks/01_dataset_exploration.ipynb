{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFashion2 Dataset Subset Creation\n",
    "\n",
    "This notebook will create a stratified train and val subset for our experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Project Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to original DeepFashion2 data\n",
    "TRAIN_IMG_DIR = \"../data/original/train/image\"\n",
    "TRAIN_ANNO_DIR = \"../data/original/train/annos\"\n",
    "VAL_IMG_DIR   = \"../data/original/validation/image\"\n",
    "VAL_ANNO_DIR  = \"../data/original/validation/annos\"\n",
    "\n",
    "# Paths to new subset (train and val)\n",
    "SUBSET_TRAIN_IMG_DIR = \"../data/subset/train/images\"\n",
    "SUBSET_TRAIN_ANNO_DIR = \"../data/subset/train/annotations\"\n",
    "SUBSET_VAL_IMG_DIR   = \"../data/subset/val/images\"\n",
    "SUBSET_VAL_ANNO_DIR  = \"../data/subset/val/annotations\"\n",
    "\n",
    "# Number of samples per category\n",
    "DESIRED_TRAIN_PER_CAT = 500\n",
    "DESIRED_VAL_PER_CAT   = 100\n",
    "\n",
    "# Map category ID to category name\n",
    "category_map = {\n",
    "    1:  \"short_sleeve_top\",\n",
    "    2:  \"long_sleeve_top\",\n",
    "    3:  \"short_sleeve_outwear\",\n",
    "    4:  \"long_sleeve_outwear\",\n",
    "    5:  \"vest\",\n",
    "    6:  \"sling\",\n",
    "    7:  \"shorts\",\n",
    "    8:  \"trousers\",\n",
    "    9:  \"skirt\",\n",
    "    10: \"short_sleeve_dress\",\n",
    "    11: \"long_sleeve_dress\",\n",
    "    12: \"vest_dress\",\n",
    "    13: \"sling_dress\"\n",
    "}\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "os.makedirs(SUBSET_TRAIN_IMG_DIR, exist_ok=True)\n",
    "os.makedirs(SUBSET_TRAIN_ANNO_DIR, exist_ok=True)\n",
    "os.makedirs(SUBSET_VAL_IMG_DIR,   exist_ok=True)\n",
    "os.makedirs(SUBSET_VAL_ANNO_DIR,  exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Stratified Subset\n",
    "\n",
    "Create a balanced subset with equal representation of all 13 clothing categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dominant_item(annotation_data):\n",
    "    # Find the item with the largest bounding box area.\n",
    "    # Returns (cat_id, bbox, item_key) or None if no items found\n",
    "    largest_area = 0\n",
    "    dominant_cat_id = None\n",
    "\n",
    "    i = 1\n",
    "    while True:\n",
    "        item_key = f\"item{i}\"\n",
    "        if item_key not in annotation_data:\n",
    "            break\n",
    "        item = annotation_data[item_key]\n",
    "        cat_id = item[\"category_id\"]\n",
    "        bbox = item[\"bounding_box\"]\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        area = (x2 - x1) * (y2 - y1)\n",
    "        if area > largest_area:\n",
    "            largest_area = area\n",
    "            dominant_cat_id = cat_id\n",
    "        i += 1\n",
    "\n",
    "    return dominant_cat_id\n",
    "\n",
    "\n",
    "def parse_dataset(img_dir, anno_dir):\n",
    "    # Parse all JSON annotations in 'anno_dir'. For each file, pick the largest bounding\n",
    "    # box item as the 'dominant' item. Return a dict:\n",
    "    # category_index[cat_id] = list of (image_filename, annotation_filename)\n",
    "\n",
    "    category_index = defaultdict(list)\n",
    "    all_anno_files = [f for f in os.listdir(anno_dir) if f.endswith(\".json\")]\n",
    "    for anno_file in all_anno_files:\n",
    "\n",
    "        image_id = os.path.splitext(anno_file)[0]\n",
    "        img_filename = image_id + \".jpg\"\n",
    "\n",
    "        anno_path = os.path.join(anno_dir, anno_file)\n",
    "        img_path  = os.path.join(img_dir,  img_filename)\n",
    "\n",
    "        if not os.path.isfile(img_path):\n",
    "            continue\n",
    "\n",
    "        with open(anno_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        dominant_cat_id = find_dominant_item(data)\n",
    "        if dominant_cat_id is not None:\n",
    "            category_index[dominant_cat_id].append((img_filename, anno_file))\n",
    "\n",
    "    return category_index\n",
    "\n",
    "\n",
    "def sample_category_items(category_index, desired_count):\n",
    "    # Shuffle each category's list and take up to 'desired_count' samples\n",
    "    # Returns a dict with the same keys but truncated lists\n",
    "\n",
    "    sampled = {}\n",
    "    for cat_id, items in category_index.items():\n",
    "        random.shuffle(items)\n",
    "        sampled[cat_id] = items[:desired_count]\n",
    "    return sampled\n",
    "\n",
    "def copy_subset_to_folder(sample_dict, src_img_dir, src_anno_dir, dst_img_dir, dst_anno_dir, csv_path):\n",
    "    # Given a dict {cat_id -> list of (img_file, anno_file)}, copy files\n",
    "    # into the subset folder structure, and write a CSV with columns:\n",
    "    # image_filename, annotation_filename, category_id, category_name\n",
    "\n",
    "    with open(csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"image_filename\", \"annotation_filename\", \"category_id\", \"category_name\"])\n",
    "\n",
    "        # For each category\n",
    "        for cat_id, items in sample_dict.items():\n",
    "            cat_name = category_map.get(cat_id, f\"cat_{cat_id}\")\n",
    "            for (img_file, anno_file) in items:\n",
    "                # Copy image\n",
    "                src_img_path  = os.path.join(src_img_dir,  img_file)\n",
    "                dst_img_path  = os.path.join(dst_img_dir,  img_file)\n",
    "                # Copy annotation\n",
    "                src_anno_path = os.path.join(src_anno_dir, anno_file)\n",
    "                dst_anno_path = os.path.join(dst_anno_dir, anno_file)\n",
    "                shutil.copyfile(src_img_path,  dst_img_path)\n",
    "                shutil.copyfile(src_anno_path, dst_anno_path)\n",
    "\n",
    "                writer.writerow([img_file, anno_file, cat_id, cat_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing TRAIN annotations...\n",
      "Found dominant items in 191961 train images total.\n",
      "Parsing VAL annotations...\n",
      "Found dominant items in 32153 val images total.\n"
     ]
    }
   ],
   "source": [
    "print(\"Parsing TRAIN annotations...\")\n",
    "train_index = parse_dataset(TRAIN_IMG_DIR, TRAIN_ANNO_DIR)\n",
    "print(f\"Found dominant items in {sum(len(v) for v in train_index.values())} train images total.\")\n",
    "\n",
    "print(\"Parsing VAL annotations...\")\n",
    "val_index = parse_dataset(VAL_IMG_DIR, VAL_ANNO_DIR)\n",
    "print(f\"Found dominant items in {sum(len(v) for v in val_index.values())} val images total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 1 (train): 500 / 500\n",
      "Category 1 (val):   100 / 100\n",
      "Category 2 (train): 500 / 500\n",
      "Category 2 (val):   100 / 100\n",
      "Category 3 (train): 461 / 500\n",
      "Category 3 (val):   100 / 100\n",
      "Category 4 (train): 500 / 500\n",
      "Category 4 (val):   100 / 100\n",
      "Category 5 (train): 500 / 500\n",
      "Category 5 (val):   100 / 100\n",
      "Category 6 (train): 500 / 500\n",
      "Category 6 (val):   100 / 100\n",
      "Category 7 (train): 500 / 500\n",
      "Category 7 (val):   100 / 100\n",
      "Category 8 (train): 500 / 500\n",
      "Category 8 (val):   100 / 100\n",
      "Category 9 (train): 500 / 500\n",
      "Category 9 (val):   100 / 100\n",
      "Category 10 (train): 500 / 500\n",
      "Category 10 (val):   100 / 100\n",
      "Category 11 (train): 500 / 500\n",
      "Category 11 (val):   100 / 100\n",
      "Category 12 (train): 500 / 500\n",
      "Category 12 (val):   100 / 100\n",
      "Category 13 (train): 500 / 500\n",
      "Category 13 (val):   100 / 100\n"
     ]
    }
   ],
   "source": [
    "train_samples = sample_category_items(train_index, DESIRED_TRAIN_PER_CAT)\n",
    "val_samples   = sample_category_items(val_index,   DESIRED_VAL_PER_CAT)\n",
    "\n",
    "for cat_id in range(1, 14):\n",
    "    print(f\"Category {cat_id} (train): {len(train_samples.get(cat_id, []))} / {DESIRED_TRAIN_PER_CAT}\")\n",
    "    print(f\"Category {cat_id} (val):   {len(val_samples.get(cat_id, []))} / {DESIRED_VAL_PER_CAT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done creating train and val subsets\n"
     ]
    }
   ],
   "source": [
    "train_csv_path = os.path.join(os.path.dirname(SUBSET_TRAIN_IMG_DIR), \"classification_metadata.csv\")  \n",
    "copy_subset_to_folder(\n",
    "    train_samples,\n",
    "    src_img_dir=TRAIN_IMG_DIR,\n",
    "    src_anno_dir=TRAIN_ANNO_DIR,\n",
    "    dst_img_dir=SUBSET_TRAIN_IMG_DIR,\n",
    "    dst_anno_dir=SUBSET_TRAIN_ANNO_DIR,\n",
    "    csv_path=train_csv_path\n",
    ")\n",
    "\n",
    "val_csv_path = os.path.join(os.path.dirname(SUBSET_VAL_IMG_DIR), \"classification_metadata.csv\")\n",
    "copy_subset_to_folder(\n",
    "    val_samples,\n",
    "    src_img_dir=VAL_IMG_DIR,\n",
    "    src_anno_dir=VAL_ANNO_DIR,\n",
    "    dst_img_dir=SUBSET_VAL_IMG_DIR,\n",
    "    dst_anno_dir=SUBSET_VAL_ANNO_DIR,\n",
    "    csv_path=val_csv_path\n",
    ")\n",
    "\n",
    "print(\"Done creating train and val subsets\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clothing-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21 (main, Dec 11 2024, 10:21:40) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "403f07482358ebae634d863ab8a0c33a06280500a45551c569a8f325de65c2a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
